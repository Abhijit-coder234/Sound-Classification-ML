{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP19BBVUzH9L9CqBnDSJoxv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijit-coder234/Sound-Classification-ML/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0hXiEvpdTZl"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split \n",
        "from os import path, getcwd, chdir\n",
        " \n",
        "local_zip = '/Spectrograms.zip' \n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/Spectrograms')\n",
        "zip_ref.close()\n",
        " \n",
        "train_BareFoot_dir = os.path.join('/Spectrograms/Train/BareFoot')\n",
        "train_Grass_dir = os.path.join('/Spectrograms/Train/Grass')\n",
        "train_MetalSurface_dir = os.path.join('/Spectrograms/Train/MetalSurface')\n",
        " \n",
        "Validations_BareFoot_dir = os.path.join('/Spectrograms/Validations/BareFoot')\n",
        "Validations_Grass_dir = os.path.join('/Spectrograms/Validations/Grass')\n",
        "Validations_MetalSurface_dir = os.path.join('/Spectrograms/Validations/MetalSurface')\n",
        " \n",
        "train_BareFoot_names = os.listdir(train_BareFoot_dir)\n",
        "print(train_BareFoot_names[:10])\n",
        "train_Grass_names = os.listdir(train_Grass_dir)\n",
        "print(train_Grass_names[:10])\n",
        "train_MetalSurface_names = os.listdir(train_MetalSurface_dir)\n",
        "print(train_MetalSurface_names[:10])\n",
        " \n",
        "Validations_BareFoot_names = os.listdir(Validations_BareFoot_dir)\n",
        "print(Validations_BareFoot_names[:10])\n",
        "Validations_Grass_names = os.listdir(Validations_Grass_dir)\n",
        "print(Validations_Grass_names[:10])\n",
        "Validations_MetalSurface_names = os.listdir(Validations_MetalSurface_dir)\n",
        "print(Validations_MetalSurface_names[:10])\n",
        " \n",
        "print('total training BareFoot images:', len(os.listdir(train_BareFoot_dir)))\n",
        "print('total training Grass images:', len(os.listdir(train_Grass_dir)))\n",
        "print('total training MetalSurface images:', len(os.listdir(train_MetalSurface_dir)))\n",
        " \n",
        "print('total validation BareFoot images:', len(os.listdir(Validations_BareFoot_dir)))\n",
        "print('total validation Grass images:', len(os.listdir(Validations_Grass_dir)))\n",
        "print('total validation MetalSurface images:', len(os.listdir(Validations_MetalSurface_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUi4tQgUd-Nk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa15e65-e87f-4fcc-c67e-c1e641d2f1b9"
      },
      "source": [
        "    # DESIRED_ACCURACY = 0.90\n",
        " \n",
        "    #  class myCallback(tf.keras.callbacks.Callback):\n",
        "    #      def on_epoch_end(self, epoch, logs={}):\n",
        "    #          if(logs.get('acc')>DESIRED_ACCURACY):\n",
        "    #             print(\"Reached above 90.0% accuracy so cancelling training!\")\n",
        "    #             self.model.stop_training = True\n",
        "        \n",
        " \n",
        "    # callbacks = myCallback()\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(41, 60, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #tf.keras.layers.MaxPooling2D(2,2),\n",
        "        #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        #tf.keras.layers.MaxPooling2D(2,2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        " \n",
        "    model.summary()\n",
        " \n",
        "    from tensorflow.keras.optimizers import RMSprop\n",
        " \n",
        "    model.compile(loss='categorical_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['accuracy'])\n",
        " \n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "    Validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        " \n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        '/Spectrograms/Train/',\n",
        "        target_size=(40, 61),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')\n",
        "    \n",
        "    Validation_generator = Validation_datagen.flow_from_directory(\n",
        "        '/Spectrograms/Validations/',\n",
        "        target_size=(40,61),\n",
        "        batch_size=10,\n",
        "        class_mode='categorical')\n",
        "  \n",
        "    history = model.fit(train_generator, \n",
        "                                  steps_per_epoch=70, \n",
        "                                  epochs=15, \n",
        "                                  verbose=1, \n",
        "                                  validation_data = Validation_generator,\n",
        "                                  validation_steps=24\n",
        "                                  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 39, 58, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 19, 29, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 17, 27, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 8, 13, 16)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 6, 11, 32)         4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 3, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 480)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               61568     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 69,363\n",
            "Trainable params: 69,363\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Found 706 images belonging to 3 classes.\n",
            "Found 240 images belonging to 3 classes.\n",
            "Epoch 1/15\n",
            "70/70 [==============================] - 2s 29ms/step - loss: 0.9798 - accuracy: 0.4957 - val_loss: 0.6571 - val_accuracy: 0.9000\n",
            "Epoch 2/15\n",
            "70/70 [==============================] - 2s 27ms/step - loss: 0.5721 - accuracy: 0.7658 - val_loss: 0.3949 - val_accuracy: 0.8708\n",
            "Epoch 3/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.4061 - accuracy: 0.8448 - val_loss: 0.3556 - val_accuracy: 0.8500\n",
            "Epoch 4/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.3243 - accuracy: 0.8563 - val_loss: 0.2411 - val_accuracy: 0.9625\n",
            "Epoch 5/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.2579 - accuracy: 0.9239 - val_loss: 0.6928 - val_accuracy: 0.6958\n",
            "Epoch 6/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.2361 - accuracy: 0.9138 - val_loss: 0.2081 - val_accuracy: 0.9125\n",
            "Epoch 7/15\n",
            "70/70 [==============================] - 2s 30ms/step - loss: 0.2070 - accuracy: 0.9253 - val_loss: 0.1762 - val_accuracy: 0.9458\n",
            "Epoch 8/15\n",
            "70/70 [==============================] - 2s 29ms/step - loss: 0.1912 - accuracy: 0.9339 - val_loss: 0.5505 - val_accuracy: 0.7542\n",
            "Epoch 9/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.1704 - accuracy: 0.9397 - val_loss: 0.2294 - val_accuracy: 0.9042\n",
            "Epoch 10/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.1387 - accuracy: 0.9483 - val_loss: 0.2698 - val_accuracy: 0.8875\n",
            "Epoch 11/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.1045 - accuracy: 0.9698 - val_loss: 0.1567 - val_accuracy: 0.9208\n",
            "Epoch 12/15\n",
            "70/70 [==============================] - 2s 31ms/step - loss: 0.0866 - accuracy: 0.9698 - val_loss: 0.1920 - val_accuracy: 0.9250\n",
            "Epoch 13/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.0942 - accuracy: 0.9713 - val_loss: 0.2528 - val_accuracy: 0.8833\n",
            "Epoch 14/15\n",
            "70/70 [==============================] - 2s 29ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.3427 - val_accuracy: 0.8500\n",
            "Epoch 15/15\n",
            "70/70 [==============================] - 2s 28ms/step - loss: 0.0566 - accuracy: 0.9828 - val_loss: 0.4107 - val_accuracy: 0.8250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWtCsxFZvGqA"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        " \n",
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(40, 61))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  if classes[0][0]==1.0:\n",
        "    print(\"The audio is BareFoot\")\n",
        "  elif classes[0][1]==1.0:\n",
        "    print(\"The audio is Grass\")\n",
        "  elif classes[0][2]==1.0:\n",
        "    print(\"The audio is MetalSurface\")\n",
        "  else:\n",
        "    print(\"The audio is not recognised\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}